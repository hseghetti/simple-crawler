<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>parser.character.encoding.default</name>
        <value>utf-8</value>
    </property>
    <property>
        <name>storage.data.store.class</name>
        <value>org.apache.gora.mongodb.store.MongoStore</value>
        <description>Default class for storing data</description>
    </property>

    <property>
        <name>http.agent.name</name>
        <value>agentname</value>
    </property>

    <property>
        <name>http.content.limit</name>
        <value>-1</value>
    </property>
    <property>
        <name>generate.max.count</name>
        <value>50</value>
        <description>The maximum number of urls in a single
        fetchlist.  -1 if unlimited. The urls are counted according
        to the value of the parameter generator.count.mode.
        </description>
    </property>
    <property>
        <name>plugin.includes</name>
        <value>
            protocol-httpclient|protocol-http|urlfilter-regex|index-(basic|anchor|metadata)|headings|language-identifier|query-(basic|site|url|lang)|indexer-elastic-rest|parse-(text|html|tika|metatags)|scoring-opic|urlnormalizer-(pass|regex|basic)
        </value>
    </property>

    <!-- HTTP properties -->

    <property>
        <name>http.agent.name</name>
        <value>agentName</value>
        <description>HTTP 'User-Agent' request header. MUST NOT be empty -
        please set this to a single word uniquely related to your organization.

        NOTE: You should also check other related properties:

            http.robots.agents
            http.agent.description
            http.agent.url
            http.agent.email
            http.agent.version

        and set their values appropriately.

        </description>
    </property>

    <property>
        <name>http.robots.agents</name>
        <value>mycrawler</value>
        <description></description>
    </property>
    <property>
        <name>http.agent.description</name>
        <value>crawling</value>
        <description></description>
    </property>
    <property>
        <name>http.agent.url</name>
        <value>www.mycrawler.com</value>
        <description>Agent site</description>
    </property>
    <property>
        <name>http.agent.email</name>
        <value>crawler@crawler.com</value>
        <description>Agent email</description>
    </property>
    <property>
        <name>http.agent.version</name>
        <value>crawlerversion</value>
        <description>Agent Version</description>
    </property>

    <property>
        <name>http.timeout</name>
        <value>30000</value>
        <description>The default network timeout, in milliseconds.</description>
    </property>

    <!-- Tika Plugin properties -->
    <property>
        <name>tika.uppercase.element.names</name>
        <value>true</value>
        <description>Determines whether TikaParser should uppercase the element name while generating the DOM
            for a page, as done by Neko (used per default by parse-html)(see NUTCH-1592).
        </description>
    </property>
    <property>
        <name>tika.extractor</name>
        <value>boilerpipe</value>
        <description>
            Which text extraction algorithm to use. Valid values are: boilerpipe or none.
        </description>
    </property>
    <property>
        <name>tika.extractor.boilerpipe.algorithm</name>
        <value>ArticleExtractor</value>
        <description>
            Which Boilerpipe algorithm to use. Valid values are: DefaultExtractor, ArticleExtractor
            or CanolaExtractor.
        </description>
    </property>

    <!--elasticsearch rest properties-->
    <property>
        <name>elastic.rest.host</name>
        <value>{ELASTIC SEARCH HOST}</value>
        <description>The hostname to send documents to using Elasticsearch Jest. Both host
            and port must be defined
            and port must be defined
        </description>
    </property>

    <property>
        <name>elastic.rest.port</name>
        <value>{PORT NUMBER}</value>
        <description>The port to connect to using Elasticsearch Jest.</description>
    </property>

    <property>
        <name>elastic.rest.index</name>
        <value>nutch_rest_dtv</value>
        <description>Default index to send documents to.</description>
    </property>

    <property>
        <name>elastic.rest.trustallhostnames</name>
        <value>true</value>
        <description>true to trust elasticsearch server's certificate even if its listed domain name does not match the domain they are hosted</description>
    </property>

    <property>
        <name>elastic.rest.type</name>
        <value>doc</value>
        <description>Default type to send documents to.</description>
    </property>

    <property>
        <name>elastic.rest.max.bulk.docs</name>
        <value>250</value>
        <description>Maximum size of the bulk in number of documents.</description>
    </property>

    <property>
        <name>elastic.rest.max.bulk.size</name>
        <value>26214400</value>
        <description>Maximum size of the bulk in bytes.</description>
    </property>

    <property>
        <name>elastic.rest.https</name>
        <value>false</value>
        <description>
            "true" to enable https, "false" to disable https
            If you've disabled http access (by forcing https), be sure to
            set this to true, otherwise you might get "connection reset by peer".
        </description>
    </property>

    <property>
        <name>elastic.rest.user</name>
        <value/>
        <description>Username for auth credentials (only used when https is enabled)</description>
    </property>

    <property>
        <name>elastic.rest.password</name>
        <value/>
        <description>Password for auth credentials (only used when https is enabled)</description>
    </property>

    <property>
        <name>elastic.rest.trustallhostnames</name>
        <value>false</value>
        <description>
            "true" to trust elasticsearch server's certificate even if its listed domain name does not
            match the domain they are hosted on
            "false" to check if the elasticsearch server's certificate's listed domain is the same domain
            that it is hosted on, and if it doesn't, then fail to index
            (only used when https is enabled)
        </description>
    </property>

    <!-- Used only if plugin parse-metatags is enabled. -->
    <!-- see: https://wiki.apache.org/nutch/IndexMetatags -->
    <property>
        <name>metatags.names</name>
        <value>author,description,keywords,image,</value>
        <description>Names of the metatags to extract, separated by ','.
            Use '*' to extract all metatags. Prefixes the names with 'metatag.'
            in the parse-metadata. For instance to index description and keywords,
            you need to activate the plugin index-metadata and set the value of the
            parameter 'index.parse.md' to 'metatag.description,metatag.keywords'.
        </description>
    </property>
    <property>
        <name>index.parse.md</name>
        <value>metatag.description,metatag.keywords,metatag.author,metatag.image,h1,h2,h3</value>
        <description>
            Comma-separated list of keys to be taken from the parse metadata to generate fields.
            Can be used e.g. for 'description' or 'keywords' provided that these values are generated
            by a parser (see parse-metatags plugin)
        </description>
    </property>
    <property>
        <name>index.content.md</name>
        <value/>
        <description>
            Comma-separated list of keys to be taken from the content metadata to generate fields.
        </description>
    </property>
    <property>
        <name>index.db.md</name>
        <value/>
        <description>
            Comma-separated list of keys to be taken from the crawldb metadata to generate fields.
            Can be used to index values propagated from the seeds with the plugin urlmeta
        </description>
    </property>

    <property>
        <name>headings</name>
        <value>h1,h2,h3</value>
        <description>Comma separated list of headings to retrieve from the document</description>
    </property>

    <property>
        <name>headings.multivalued</name>
        <value>true</value>
        <description>Whether to support multivalued headings.</description>
    </property>
    <property>
    <name>elastic.host</name>
    <value>{ELASTIC SEARCH HOST}</value>
  </property>
  <property>
    <name>elastic.port</name>
    <value>{PORT NUMBER}</value>
  </property>
  <property>
    <name>elastic.cluster</name>
    <value>elasticsearch</value>
  </property>
  <property>
    <name>elastic.index</name>
    <value>nutchindex</value>
  </property>


</configuration>
